{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SahilBansal_Svm.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "rtkBTJl3T3f-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Assignment Support Vector Machienes"
      ]
    },
    {
      "metadata": {
        "id": "7RMviipgT3gA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ## Data Understanding "
      ]
    },
    {
      "metadata": {
        "id": "keuCmY8ZT3gB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.pipeline import Pipeline\n",
        "from PIL import Image\n",
        "import time\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import scale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4xYX2rZnT3gJ",
        "colab_type": "code",
        "outputId": "5ce59b3f-7020-4ded-e948-26eaa57a1da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "# reading the dataset\n",
        "train_data = pd.read_csv(\"train.csv\")\n",
        "train_data.head()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
              "0      1       0       0       0       0       0       0       0       0   \n",
              "1      0       0       0       0       0       0       0       0       0   \n",
              "2      1       0       0       0       0       0       0       0       0   \n",
              "3      4       0       0       0       0       0       0       0       0   \n",
              "4      0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
              "0       0    ...            0         0         0         0         0   \n",
              "1       0    ...            0         0         0         0         0   \n",
              "2       0    ...            0         0         0         0         0   \n",
              "3       0    ...            0         0         0         0         0   \n",
              "4       0    ...            0         0         0         0         0   \n",
              "\n",
              "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
              "0         0         0         0         0         0  \n",
              "1         0         0         0         0         0  \n",
              "2         0         0         0         0         0  \n",
              "3         0         0         0         0         0  \n",
              "4         0         0         0         0         0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "JeefR7WzT3gW",
        "colab_type": "code",
        "outputId": "d5726b91-9083-4212-9c47-2242ac85e36c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# summary of the dataset\n",
        "train_data.info()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 42000 entries, 0 to 41999\n",
            "Columns: 785 entries, label to pixel783\n",
            "dtypes: int64(785)\n",
            "memory usage: 251.5 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n02jrL_CT3gb",
        "colab_type": "code",
        "outputId": "6996ff0b-2ee9-440f-8a0e-abd3a0b73f6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# checking the dimensions\n",
        "train_data.shape"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42000, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "obsLpv08T3gf",
        "colab_type": "code",
        "outputId": "9e3c6285-e238-4ef3-8d6d-cffa827e7835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "# checking the columns\n",
        "train_data.columns"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['label', 'pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5',\n",
              "       'pixel6', 'pixel7', 'pixel8',\n",
              "       ...\n",
              "       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
              "       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
              "      dtype='object', length=785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "LKU_CxlLT3gm",
        "colab_type": "code",
        "outputId": "e3081a49-ce51-406c-ee42-84a047ff8dd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "# breaking the dataset into subset.\n",
        "# making it to 20 percent\n",
        "twentypercentsubset=train_data.sample(frac=0.2, replace=True, random_state=1)\n",
        "twentypercentsubset.head()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33003</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12172</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5192</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32511</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7813</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
              "33003      1       0       0       0       0       0       0       0       0   \n",
              "12172      1       0       0       0       0       0       0       0       0   \n",
              "5192       2       0       0       0       0       0       0       0       0   \n",
              "32511      1       0       0       0       0       0       0       0       0   \n",
              "7813       7       0       0       0       0       0       0       0       0   \n",
              "\n",
              "       pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
              "33003       0    ...            0         0         0         0         0   \n",
              "12172       0    ...            0         0         0         0         0   \n",
              "5192        0    ...            0         0         0         0         0   \n",
              "32511       0    ...            0         0         0         0         0   \n",
              "7813        0    ...            0         0         0         0         0   \n",
              "\n",
              "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
              "33003         0         0         0         0         0  \n",
              "12172         0         0         0         0         0  \n",
              "5192          0         0         0         0         0  \n",
              "32511         0         0         0         0         0  \n",
              "7813          0         0         0         0         0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "metadata": {
        "id": "VAbQu4F06VCH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c609fdfb-91ee-449e-8681-456b318d1758"
      },
      "cell_type": "code",
      "source": [
        "## checking the variance of the dataset\n",
        "varince=train_data.var()\n",
        "varince=varince.sort_values(ascending=False)\n",
        "varince.head()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pixel406    12961.855023\n",
              "pixel378    12930.525263\n",
              "pixel627    12768.248426\n",
              "pixel461    12750.287623\n",
              "pixel434    12712.507782\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "MmBNjhAjT3hB",
        "colab_type": "code",
        "outputId": "ad1cded5-29a8-4eab-a1cd-3febed9e5561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "# removing the columns with very low varinace (less than or equal to  30 percent varince)\n",
        "filteredvariance= train_data.loc[:, train_data.var() >=9073.2985161]\n",
        "filteredvariance.head()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel152</th>\n",
              "      <th>pixel153</th>\n",
              "      <th>pixel154</th>\n",
              "      <th>pixel155</th>\n",
              "      <th>pixel156</th>\n",
              "      <th>pixel157</th>\n",
              "      <th>pixel158</th>\n",
              "      <th>pixel179</th>\n",
              "      <th>pixel180</th>\n",
              "      <th>pixel181</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel631</th>\n",
              "      <th>pixel632</th>\n",
              "      <th>pixel633</th>\n",
              "      <th>pixel653</th>\n",
              "      <th>pixel654</th>\n",
              "      <th>pixel655</th>\n",
              "      <th>pixel656</th>\n",
              "      <th>pixel657</th>\n",
              "      <th>pixel658</th>\n",
              "      <th>pixel659</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>218</td>\n",
              "      <td>95</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>217</td>\n",
              "      <td>246</td>\n",
              "      <td>151</td>\n",
              "      <td>32</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>...</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>8</td>\n",
              "      <td>76</td>\n",
              "      <td>146</td>\n",
              "      <td>254</td>\n",
              "      <td>255</td>\n",
              "      <td>254</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>254</td>\n",
              "      <td>...</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>114</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>...</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>129</td>\n",
              "      <td>208</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>159</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 217 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel152  pixel153  pixel154  pixel155  pixel156  pixel157  pixel158  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254       254       254       217       246       151        32   \n",
              "2         9       254       254         8         0         0         0   \n",
              "3         0         0         0         0         0         9        77   \n",
              "4       253       253       253       253       253       253       114   \n",
              "\n",
              "   pixel179  pixel180  pixel181    ...     pixel631  pixel632  pixel633  \\\n",
              "0         0         0         0    ...            0         0         0   \n",
              "1       254       254       254    ...          254       254       254   \n",
              "2         0         9       254    ...          184         0         0   \n",
              "3         0         0         0    ...            0         0         0   \n",
              "4       253       253       253    ...          253       253       253   \n",
              "\n",
              "   pixel653  pixel654  pixel655  pixel656  pixel657  pixel658  pixel659  \n",
              "0       218        95         0         0         0         0         0  \n",
              "1         8        76       146       254       255       254       255  \n",
              "2         0         0         0        63       254       254        62  \n",
              "3         0         0         0         0         0         0         0  \n",
              "4       129       208       253       253       253       253       159  \n",
              "\n",
              "[5 rows x 217 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "u69fiX2BD7IR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YWOCjCQZT3hG",
        "colab_type": "code",
        "outputId": "6fb9f614-327f-48b1-cbae-18d77b0acd1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# checking dimensions for the subset twentypercentsubset\n",
        "twentypercentsubset.shape"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8400, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "FtDA1IqsT3hK",
        "colab_type": "code",
        "outputId": "85ca79ba-b2cd-44a9-e1e5-914559eb46db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# checking dimensions for the dataset filteredvariance\n",
        "filteredvariance.shape"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42000, 217)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "jikA6cFIT3hN",
        "colab_type": "code",
        "outputId": "c6befdcc-5bec-481d-d15a-f84175db32cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# checking the unique values in label column\n",
        "order = list(np.sort(train_data['label'].unique()))\n",
        "print(order)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kc6HxijzT3hW",
        "colab_type": "code",
        "outputId": "8c15af6d-ae1a-46fa-af52-9c52e7e0ff10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        }
      },
      "cell_type": "code",
      "source": [
        "# basic plots: How do various attributes vary with the letters\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "sns.barplot(x='label', y='pixel72', \n",
        "            data=twentypercentsubset, \n",
        "            order=order)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/categorical.py:1428: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
            "  stat_data = remove_na(group_data)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fab1af05898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6sAAAHgCAYAAABD4vsDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw9KtWoSnuwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Lfpa0NwqT3hl",
        "colab_type": "code",
        "outputId": "6bfa4356-7536-4c21-c153-ee958c82b23f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "cell_type": "code",
      "source": [
        "# grouping by label column\n",
        "twentypercentsubset_means = twentypercentsubset.groupby('label').mean()\n",
        "twentypercentsubset_means"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.317460</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.239229</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.264242</td>\n",
              "      <td>0.086061</td>\n",
              "      <td>0.305455</td>\n",
              "      <td>0.306667</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "label                                                                           \n",
              "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "5         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "6         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "7         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "8         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "9         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "\n",
              "       pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
              "label            ...                                                        \n",
              "0         0.0    ...     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "1         0.0    ...     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "2         0.0    ...     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "3         0.0    ...     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "4         0.0    ...     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "5         0.0    ...     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "6         0.0    ...     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "7         0.0    ...     1.317460  0.500000  0.239229  0.000000  0.000000   \n",
              "8         0.0    ...     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "9         0.0    ...     0.264242  0.086061  0.305455  0.306667  0.060606   \n",
              "\n",
              "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
              "label                                                    \n",
              "0           0.0       0.0       0.0       0.0       0.0  \n",
              "1           0.0       0.0       0.0       0.0       0.0  \n",
              "2           0.0       0.0       0.0       0.0       0.0  \n",
              "3           0.0       0.0       0.0       0.0       0.0  \n",
              "4           0.0       0.0       0.0       0.0       0.0  \n",
              "5           0.0       0.0       0.0       0.0       0.0  \n",
              "6           0.0       0.0       0.0       0.0       0.0  \n",
              "7           0.0       0.0       0.0       0.0       0.0  \n",
              "8           0.0       0.0       0.0       0.0       0.0  \n",
              "9           0.0       0.0       0.0       0.0       0.0  \n",
              "\n",
              "[10 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "aKrWFSbFT3hz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "metadata": {
        "id": "t1YTR2BzT3h1",
        "colab_type": "code",
        "outputId": "c86ce724-bd68-44b2-bd5b-5eced5a147ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        }
      },
      "cell_type": "code",
      "source": [
        "# average feature values\n",
        "round(twentypercentsubset.drop('label', axis=1).mean(), 2)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pixel0      0.00\n",
              "pixel1      0.00\n",
              "pixel2      0.00\n",
              "pixel3      0.00\n",
              "pixel4      0.00\n",
              "pixel5      0.00\n",
              "pixel6      0.00\n",
              "pixel7      0.00\n",
              "pixel8      0.00\n",
              "pixel9      0.00\n",
              "pixel10     0.00\n",
              "pixel11     0.00\n",
              "pixel12     0.00\n",
              "pixel13     0.00\n",
              "pixel14     0.00\n",
              "pixel15     0.00\n",
              "pixel16     0.00\n",
              "pixel17     0.00\n",
              "pixel18     0.00\n",
              "pixel19     0.00\n",
              "pixel20     0.00\n",
              "pixel21     0.00\n",
              "pixel22     0.00\n",
              "pixel23     0.00\n",
              "pixel24     0.00\n",
              "pixel25     0.00\n",
              "pixel26     0.00\n",
              "pixel27     0.00\n",
              "pixel28     0.00\n",
              "pixel29     0.00\n",
              "            ... \n",
              "pixel754    0.00\n",
              "pixel755    0.00\n",
              "pixel756    0.00\n",
              "pixel757    0.00\n",
              "pixel758    0.00\n",
              "pixel759    0.00\n",
              "pixel760    0.00\n",
              "pixel761    0.00\n",
              "pixel762    0.02\n",
              "pixel763    0.09\n",
              "pixel764    0.06\n",
              "pixel765    0.11\n",
              "pixel766    0.30\n",
              "pixel767    0.35\n",
              "pixel768    0.42\n",
              "pixel769    0.47\n",
              "pixel770    0.78\n",
              "pixel771    0.79\n",
              "pixel772    0.59\n",
              "pixel773    0.26\n",
              "pixel774    0.16\n",
              "pixel775    0.06\n",
              "pixel776    0.06\n",
              "pixel777    0.03\n",
              "pixel778    0.01\n",
              "pixel779    0.00\n",
              "pixel780    0.00\n",
              "pixel781    0.00\n",
              "pixel782    0.00\n",
              "pixel783    0.00\n",
              "Length: 784, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "metadata": {
        "id": "Ph0S9EpO53IN",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Initially i build the model by taking 20 percent of the data directly from the train data given but found the accuracy to be less than the value which we are achieving after removing the low variance columns ,hence i have commented this code here.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pLD26g-KT3iD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# # # splitting into X and y\n",
        "# X = twentypercentsubset.drop(\"label\", axis = 1)\n",
        "# y = twentypercentsubset['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5thuhWQw7tgY",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Here while using the whole train data set we get a high accuracy but computation time is very large and hence i also commented this split.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JmwaGjpZ7rpO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# # # splitting into X and y\n",
        "# X = train_data.drop(\"label\", axis = 1)\n",
        "# y = train_data['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_w2AO0888JSo",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Finally using the filteredvariance dataset where i filtered the low variance columns and used for further analysis.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fPxUv-ZT8IFg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # splitting into X and y\n",
        "X = filteredvariance\n",
        "y = train_data['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dANs7b5XT3iH",
        "colab_type": "code",
        "outputId": "4923d094-a092-4d03-d082-56f2e191a35d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# scaling the features\n",
        "X_scaled = scale(X)\n",
        "\n",
        "# train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.3, random_state = 101)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64 were all converted to float64 by the scale function.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "RE0SMO-lT3iO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model building "
      ]
    },
    {
      "metadata": {
        "id": "Thm9ngd9T3iT",
        "colab_type": "code",
        "outputId": "6b3e3794-5cab-4f3f-eaa2-838af84e1ab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# linear model\n",
        "start=time.time()\n",
        "\n",
        "\n",
        "model_linear = SVC(kernel='linear')\n",
        "model_linear.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "y_pred = model_linear.predict(X_test)\n",
        "end = time. time()\n",
        "print(end - start)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "166.95113801956177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cr87xaOWT3if",
        "colab_type": "code",
        "outputId": "4aacb1b5-1c34-47c6-ca9a-6977f1c5ccf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "# confusion matrix and accuracy\n",
        "\n",
        "# accuracy\n",
        "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
        "\n",
        "# cm\n",
        "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.9026190476190477 \n",
            "\n",
            "[[1153    0    9    5    1   23   15    0    7    0]\n",
            " [   0 1386   13    6    0    4    0    2    8    3]\n",
            " [  17   21 1090   14   18   12   37   18   20   11]\n",
            " [  13    6   22 1144    3   51    4    8   17   16]\n",
            " [   6    5   12    2 1129    4    8    7    4   32]\n",
            " [  35   12   24   74   11  918   22    3   15    7]\n",
            " [  10    5   27    9   15   30 1142    0    4    0]\n",
            " [   5    2   26    9   16    2    1 1226    5   23]\n",
            " [   9   18   29   38    9   47    9    4 1050   14]\n",
            " [   5    8   19   27   55    6    0   41   13 1135]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oDBIwPFoT3il",
        "colab_type": "code",
        "outputId": "e529e0bc-5b7c-4d55-9fa0-56f081de56a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# non-linear model\n",
        "# using rbf kernel, C=1, default value of gamma\n",
        "\n",
        "# model\n",
        "non_linear_model = SVC(kernel='rbf')\n",
        "\n",
        "# fit\n",
        "non_linear_model.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "y_pred = non_linear_model.predict(X_test)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-kFitF2BT3is",
        "colab_type": "code",
        "outputId": "76d10a39-9b6b-4e2d-d8a8-75856b7ab64e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "# confusion matrix and accuracy\n",
        "\n",
        "# accuracy\n",
        "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
        "\n",
        "# cm\n",
        "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.972936507936508 \n",
            "\n",
            "[[1201    0    3    1    1    2    3    0    2    0]\n",
            " [   0 1403    6    3    2    1    0    3    3    1]\n",
            " [   9    3 1212    4    4    1    2   14    8    1]\n",
            " [   3    0   18 1224    1   17    5    3    5    8]\n",
            " [   2    0    3    0 1187    0    3    1    3   10]\n",
            " [   3    0    1   13    3 1091    5    0    2    3]\n",
            " [   5    1    2    0    1    5 1228    0    0    0]\n",
            " [   2    2   15    2   11    0    0 1273    1    9]\n",
            " [   2    2    7    7    4    2    3    1 1195    4]\n",
            " [   6    3    4   11   20    2    1    8    9 1245]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R5t4Sur_T3i1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Grid Search: Hyperparameter Tuning Let's now tune the model to find the optimal values of C and gamma corresponding to an RBF kernel. We'll use 5-fold cross validation."
      ]
    },
    {
      "metadata": {
        "id": "9STQkH0kT3i3",
        "colab_type": "code",
        "outputId": "793ca99d-1b75-476a-fae3-385a5808875d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# creating a KFold object with 5 splits \n",
        "folds = KFold(n_splits = 5, shuffle = True, random_state = 101)\n",
        "\n",
        "# specify range of hyperparameters\n",
        "# Set the parameters by cross-validation\n",
        "hyper_params = [ {'gamma': [1e-2, 1e-3, 1e-4],\n",
        "                     'C': [1, 10, 100, 1000]}]\n",
        "\n",
        "\n",
        "# specify model\n",
        "model = SVC(kernel=\"rbf\")\n",
        "\n",
        "# set up GridSearchCV()\n",
        "model_cv = GridSearchCV(estimator = model, \n",
        "                        param_grid = hyper_params, \n",
        "                        scoring= 'accuracy', \n",
        "                        cv = folds, \n",
        "                        verbose = 1,\n",
        "                        return_train_score=True)      \n",
        "\n",
        "# fit the model\n",
        "model_cv.fit(X_train, y_train)       "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "MDAGKWFeT3jN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# cv results\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "cv_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wWqhzjo2T3jU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# converting C to numeric type for plotting on x-axis\n",
        "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
        "\n",
        "# # plotting\n",
        "plt.figure(figsize=(16,6))\n",
        "\n",
        "# subplot 1/3\n",
        "plt.subplot(131)\n",
        "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
        "\n",
        "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
        "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(\"Gamma=0.01\")\n",
        "plt.ylim([0.60, 1])\n",
        "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
        "plt.xscale('log')\n",
        "\n",
        "# subplot 2/3\n",
        "plt.subplot(132)\n",
        "gamma_001 = cv_results[cv_results['param_gamma']==0.001]\n",
        "\n",
        "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
        "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(\"Gamma=0.001\")\n",
        "plt.ylim([0.60, 1])\n",
        "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
        "plt.xscale('log')\n",
        "\n",
        "\n",
        "# subplot 3/3\n",
        "plt.subplot(133)\n",
        "gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n",
        "\n",
        "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
        "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(\"Gamma=0.0001\")\n",
        "plt.ylim([0.60, 1])\n",
        "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
        "plt.xscale('log')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vk3ypUBQT3jY",
        "colab_type": "code",
        "outputId": "61126754-70ef-47d3-b9ed-af3ee607a646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# printing the optimal accuracy score and hyperparameters\n",
        "best_score = model_cv.best_score_\n",
        "best_hyperparams = model_cv.best_params_\n",
        "\n",
        "print(\"The score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The score is 0.9569654703180813 corresponding to hyperparameters {'C': 10, 'gamma': 0.01}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OTJT_7C-T3ja",
        "colab_type": "code",
        "outputId": "24ccf11b-a1f6-4f9b-a112-217555723614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "# model with optimal hyperparameters\n",
        "\n",
        "# model\n",
        "model = SVC(C=10, gamma=0.01, kernel=\"rbf\")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# metrics\n",
        "print(\"accuracy\", metrics.accuracy_score(y_test, y_pred), \"\\n\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred), \"\\n\")\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.9793650793650793 \n",
            "\n",
            "[[1206    0    2    1    1    0    1    0    2    0]\n",
            " [   0 1401    8    3    3    1    0    3    3    0]\n",
            " [   5    2 1227    3    1    3    2    8    7    0]\n",
            " [   1    0   13 1244    0   11    5    2    5    3]\n",
            " [   1    0    2    0 1196    0    3    0    2    5]\n",
            " [   1    1    0   12    2 1091    6    0    3    5]\n",
            " [   4    1    1    0    1    3 1232    0    0    0]\n",
            " [   1    3    7    2   10    0    0 1286    0    6]\n",
            " [   0    1    6    7    1    0    2    1 1205    4]\n",
            " [   5    2    3   10   20    3    1    5    8 1252]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zoKWlIMaSrTl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "08ce214d-c0d9-44f3-f9d7-55dcd8cb759e"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#  polynomial model\n",
        "\n",
        "polynomial_model = SVC(kernel='poly',degree=2)\n",
        "\n",
        "# fit\n",
        "polynomial_model.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "y_pred =polynomial_model.predict(X_test)\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "bOM1_qg5kzXR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "42b5ae57-34bc-4472-8687-84a78eba2f49"
      },
      "cell_type": "code",
      "source": [
        "# confusion matrix and accuracy\n",
        "\n",
        "# accuracy\n",
        "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
        "\n",
        "# cm\n",
        "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.9719047619047619 \n",
            "\n",
            "[[1199    0    4    2    1    1    2    0    2    2]\n",
            " [   2 1399    8    0    7    1    1    3    1    0]\n",
            " [   7    2 1216    3    8    1    2   12    3    4]\n",
            " [   2    0   19 1220    1   24    3    4    6    5]\n",
            " [   3    2    3    2 1190    0    4    0    0    5]\n",
            " [   1    0    2   13    0 1090    5    1    5    4]\n",
            " [   7    0    2    1    1    6 1222    0    3    0]\n",
            " [   3    2   14    1   10    1    0 1271    1   12]\n",
            " [   2    2   12    8    1    3    3    1 1193    2]\n",
            " [   6    4    5    9   15    5    2    9    8 1246]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nFV3DVvHrD9-",
        "colab_type": "code",
        "outputId": "b8a44738-05e1-4fb4-d7f6-94d36d0552aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "cell_type": "code",
      "source": [
        "# Plotting some samples \n",
        "\n",
        "four = train_data.iloc[3, 1:]\n",
        "four.shape\n",
        "four = four.values.reshape(28,28)\n",
        "plt.imshow(four, cmap='gray')\n",
        "plt.title(\"Digit 4\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Digit 4')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFZCAYAAAARqQ0OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSwAwICwBwICwBAADwhIADP4PPby3CWohHgMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "EOqiXugMAf0K",
        "colab_type": "code",
        "outputId": "53bef917-7895-4ac1-8634-ffad2f46fc13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# for digits 7\n",
        "seven = train_data.iloc[6, 1:]\n",
        "seven.shape\n",
        "seven = seven.values.reshape(28, 28)\n",
        "plt.imshow(seven, cmap='gray')\n",
        "plt.title(\"Digit 7\")"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Digit 7')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFZCAYAAAARqQ0OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "8mD_qIR9XPCw",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title The aacuracy for twenty percent of the data is more but at the same time the computation time is very high and accuracy for the dataset with low variance columns is low as compared to the filtereddataset which i used for computation , as this dataset does not contains low variance columns and i have also filtered the rows according to each label value\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}